{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style='text-align: center; color: lightblue; font-size: 40px'> Unet </h1>\n",
    "<h2 style='text-align: center; color: lightblue; font-size: 30px'> another kind of autoencoder ? </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An introduction to reading research papers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "research papers usually follow a pattern:\n",
    "* they introduce what they will say, and immediately give the main takeaways\n",
    "* they compare their work to current work in the field\n",
    "* they enter the details of their procedure\n",
    "* they give detailed results, usually using benchmarks to make comparisons with other approaches\n",
    "* they wrap up, saying again what their work adds to previous knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read this paper: https://arxiv.org/pdf/1505.04597.pdf and try to understand what happens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to answer two questions:\n",
    "\n",
    "* what are the similarities of Unet with Autoencoders ?\n",
    "* what is done differently here ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding tree surfaces: \n",
    "https://medium.com/nam-r/estimating-vegetated-surfaces-with-computer-vision-how-we-improved-our-model-and-scaled-up-66426b6e9fc6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/unet-namr.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Medical imaging:\n",
    "<img src='images/SIIM-pneumotorax.png'> </img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/SIIM-unet.png'> </img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## De-Oldify: \n",
    "https://github.com/jantic/DeOldify\n",
    "<img src='images/deoldify-cafe.jpeg'> </img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unets with fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deoldify-cafe.jpeg\n",
      "fastai-segmentation-exercices.png\n",
      "fastai-segmentation-intro.png\n",
      "LSTMCELL.png\n",
      "nnet-error-functions2.png\n",
      "RNN-cell.png\n",
      "RNN-schema2.png\n",
      "RNN-schema.png\n",
      "SIIM-pneumotorax.png\n",
      "SIIM-unet.png\n",
      "target-encoding.png\n",
      "unet-namr.png\n",
      "word2vec_diagrams.png\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd images\n",
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/fastai-segmentation-intro1.png'> </img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Note: look at Lesson3 exercises1 - multilabel classification to know how to get the data </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/fastai-segmentation-exercices1.png'> </img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
