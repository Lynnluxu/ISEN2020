{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style='text-align: center; color: lightblue; font-size: 40px'> Metrics, and data Ethics </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Metrics fundamentals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## MSE vs. MAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<img src='images/MAEvsMSE.png' style='align: left'></img> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Which is which ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "You want to predict people's age based on their photo, which one do you pick ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "You want to predict building's energy consumption, which one do you pick ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "You want to predict appartment prices based on their features, which one do you pick ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Accuracy, precision, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<img src='images/conf_matrix.png'></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<img src='images/conf_matrix2.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<h2> In code: </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "actual = np.array([0,0,0,0,0,1,1,1,1,1])\n",
    "predicted = np.array([0,0,0,0,0,1,1,1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 0],\n",
       "       [0, 5]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(actual, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(actual, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 0],\n",
       "       [5, 0]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual = np.array([0,0,0,0,0,1,1,1,1,1])\n",
    "predicted = np.array([0,0,0,0,0,0,0,0,0,0]) #all zeros\n",
    "confusion_matrix(actual, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 5],\n",
       "       [0, 5]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual = np.array([0,0,0,0,0,1,1,1,1,1])\n",
    "predicted = np.array([1,1,1,1,1,1,1,1,1,1]) #all ones\n",
    "confusion_matrix(actual, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The numbers don't look like the above diagrams. Do you know why ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "??confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 0],\n",
       "       [1, 4]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual = np.array([0,0,0,0,0,1,1,1,1,1])\n",
    "predicted = np.array([0,0,0,0,0,0,1,1,1,1]) #changed one 1 into 0\n",
    "confusion_matrix(actual, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is from the above documentation:\n",
    "tn, fp, fn, tp = confusion_matrix(actual, predicted).ravel()\n",
    "# the bottom right number is true positive, whereas in the above matrix TP is top left !\n",
    "tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 0],\n",
       "       [5, 0]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can rearrange the confusion matrix like this:\n",
    "confusion_matrix(actual, predicted, labels=[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.metrics import ...  # no specificity ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Well, specificity becomes recall if you reverse your confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "specificity= 1.0\n",
      "recall= 0.8\n",
      "recall sklearn: 0.8\n",
      "specificity sklearn: 0.8\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(actual, predicted).ravel()\n",
    "# the bottom right number is true positive, whereas in the above matrix TP is top left !\n",
    "print(\"specificity=\", tn / (tn +fp))\n",
    "print(\"recall=\", tp / (tp + fn))\n",
    "print(\"recall sklearn:\", recall_score(actual, predicted))\n",
    "print(\"specificity sklearn:\", recall_score(actual, predicted, labels=[1,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<h2> In the end, what do you care about ? </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- SPAM: Specificity (you want as few FP as possible)\n",
    "- CANCER DETECTION: Recall (you want as few FN as possible) \n",
    "- Classify cat vs. dog: well, what's more important to you ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Loss functions in DL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Recap of class:\n",
    "\n",
    "* Why is MSE not suited for classification ?\n",
    "* Why is CrossEntropy not suited for multi-label classification ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Another example: focal loss:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "\\begin{equation}\n",
    "\\mathrm{FL}\\left(p_{\\mathrm{t}}\\right)=-\\left(1-p_{\\mathrm{t}}\\right)^{\\gamma} \\log \\left(p_{\\mathrm{t}}\\right)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Where: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "\\begin{equation}\n",
    "p_{\\mathrm{t}}=\\left\\{\\begin{array}{ll}\n",
    "{p} & {\\text { if } y=1} \\\\\n",
    "{1-p} & {\\text { otherwise }}\n",
    "\\end{array}\\right.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10536051565782628\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0010536051565782623"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the model classifies correctly\n",
    "p = 0.9\n",
    "y = 1\n",
    "\n",
    "print(-np.log(p))\n",
    "-(1-p)**2 * np.log(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6931471805599453\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.17328679513998632"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the model is unsure\n",
    "p = 0.5\n",
    "y = 1\n",
    "\n",
    "print(-np.log(p))\n",
    "-(1-p)**2 * np.log(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Which loss for which problem ? \n",
    "\n",
    "awesome recap:\n",
    "https://heartbeat.fritz.ai/research-guide-advanced-loss-functions-for-machine-learning-models-aee68ed8a38c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The importance of well-defined metrics and losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In traditionnal ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a very imbalanced classification problem\n",
    "actual = (np.random.rand(1000) > 0.99).astype(int)\n",
    "actual.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.005\n",
      "recall: 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  0, 995],\n",
       "       [  0,   5]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = np.ones(1000)\n",
    "preds[0] = 1\n",
    "print(\"precision:\", precision_score(actual, preds))\n",
    "print(\"recall:\", recall_score(actual, preds))\n",
    "confusion_matrix(actual, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.0\n",
      "recall: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[994,   1],\n",
       "       [  5,   0]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = np.zeros(1000)\n",
    "preds[0] = 1\n",
    "print(\"precision:\", precision_score(actual, preds))\n",
    "print(\"recall:\", recall_score(actual, preds))\n",
    "confusion_matrix(actual, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a better model:\n",
    "preds = actual.copy()\n",
    "for i in range(len(preds[preds == 0])):\n",
    "    if np.random.randn() > 0.95:\n",
    "        preds[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.026455026455026454\n",
      "recall: 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[811, 184],\n",
       "       [  0,   5]])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I found all the anomalies I was looking for, but it cost me more than 100 useless checks\n",
    "print(\"precision:\", precision_score(actual, preds))\n",
    "print(\"recall:\", recall_score(actual, preds))\n",
    "confusion_matrix(actual, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[811 184]\n",
      " [  4   1]]\n",
      "[[811 184]\n",
      " [  1   4]]\n"
     ]
    }
   ],
   "source": [
    "# Compare these models : \n",
    "print(np.array([[811, 184],\n",
    "           [  4,   1]]))\n",
    "\n",
    "print(np.array([[811, 184],\n",
    "           [  1,   4]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which one is better ? Why ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.washingtonpost.com/local/education/creative--motivating-and-fired/2012/02/04/gIQAwzZpvR_story.html\n",
    "\n",
    "TL;DR:\n",
    "A teacher was fired, yet everyone (principal, parents) thought she was a great teacher. What happened ?\n",
    "- she was judged by her ability to improve students' performance\n",
    "- how is student performance measured ? Test scores\n",
    "- if a student was \"below expectations\" at reading at year N-1 and \"meeting expectations\" at year N, then the teacher has done a good job\n",
    "- what is the problem with that ?\n",
    "\n",
    "for more on mass students testing, read Freakonomics :\n",
    "https://www.gradesaver.com/freakonomics/study-guide/summary-chapter-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CoastRunners: https://openai.com/blog/faulty-reward-functions/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Problems when metrics confront, like in GANS: which one to optimize ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Essay grading: \n",
    "\n",
    "https://www.vice.com/en_us/article/pa7dj9/flawed-algorithms-are-grading-millions-of-students-essays\n",
    "\n",
    "short story: \n",
    "\n",
    "Several years ago, Les Perelman, the former director of writing across the curriculum at MIT, and a group of students developed the Basic Automatic B.S. Essay Language (BABEL) Generator, a program that patched together strings of sophisticated words and sentences into meaningless gibberish essays. The nonsense essays consistently received high, sometimes perfect, scores when run through several different scoring engines\n",
    "\n",
    "Motherboard replicated the experiment. We submitted two BABEL-generated essays—one in the “issue” category, the other in the “argument” category—to the GRE’s online ScoreItNow! practice tool, which uses E-rater. Both received scores of 4 out of 6, indicating the essays displayed “competent examination of the argument and convey(ed) meaning with acceptable clarity.”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- More: see book \"Weapons of Math Destruction\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# In AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Tim Urban's world-reknown blog post on AS(super)I:\n",
    "\n",
    "https://waitbutwhy.com/2015/01/artificial-intelligence-revolution-1.html\n",
    "\n",
    "\n",
    "The answer isn’t anything surprising—AI thinks like a computer, because that’s what it is. But when we think about highly intelligent AI, we make the mistake of anthropomorphizing AI (projecting human values on a non-human entity) because we think from a human perspective and because in our current world, the only things with human-level intelligence are humans. To understand ASI, we have to wrap our heads around the concept of something both smart and totally alien.\n",
    "\n",
    "Let me draw a comparison. If you handed me a guinea pig and told me it definitely won’t bite, I’d probably be amused. It would be fun. If you then handed me a tarantula and told me that it definitely won’t bite, I’d yell and drop it and run out of the room and not trust you ever again. But what’s the difference? Neither one was dangerous in any way. I believe the answer is in the animals’ degree of similarity to me.\n",
    "\n",
    "A guinea pig is a mammal and on some biological level, I feel a connection to it—but a spider is an insect,18 with an insect brain, and I feel almost no connection to it. The alien-ness of a tarantula is what gives me the willies. To test this and remove other factors, if there are two guinea pigs, one normal one and one with the mind of a tarantula, I would feel much less comfortable holding the latter guinea pig, even if I knew neither would hurt me.\n",
    "\n",
    "Now imagine that you made a spider much, much smarter—so much so that it far surpassed human intelligence? Would it then become familiar to us and feel human emotions like empathy and humor and love? No, it wouldn’t, because there’s no reason becoming smarter would make it more human—it would be incredibly smart but also still fundamentally a spider in its core inner workings. I find this unbelievably creepy. I would not want to spend time with a superintelligent spider. Would you??\n",
    "\n",
    "When we’re talking about ASI, the same concept applies—it would become superintelligent, but it would be no more human than your laptop is. It would be totally alien to us—in fact, by not being biology at all, it would be more alien than the smart tarantula.\n",
    "\n",
    "\n",
    "[....]\n",
    "\n",
    "\n",
    "\n",
    "For example, what if we try to align an AI system’s values with our own and give it the goal, “Make people happy”?\n",
    "\n",
    "Once it becomes smart enough, it figures out that it can most effectively achieve this goal by implanting electrodes inside people’s brains and stimulating their pleasure centers. Then it realizes it can increase efficiency by shutting down other parts of the brain, leaving all people as happy-feeling unconscious vegetables. If the command had been “Maximize human happiness,” it may have done away with humans all together in favor of manufacturing huge vats of human brain mass in an optimally happy state. We’d be screaming Wait that’s not what we meant! as it came for us, but it would be too late. The system wouldn’t let anyone get in the way of its goal.\n",
    "\n",
    "If we program an AI with the goal of doing things that make us smile, after its takeoff, it may paralyze our facial muscles into permanent smiles. Program it to keep us safe, it may imprison us at home. Maybe we ask it to end all hunger, and it thinks “Easy one!” and just kills all humans. Or assign it the task of “Preserving life as much as possible,” and it kills all humans, since they kill more life on the planet than any other species."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Metrics in life: is our loss what we call \"interest\" ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "There are three kinds of incentives: economic, social, and moral, and often incentive schemes will include all three of these. Levitt uses crime as an example: why don't more people commit crimes? Because there exist economic incentives—being jailed, losing your house, being fined—that stop us from doing so, as well as moral incentives, like the refusal to do something morally wrong, and social incentives–we do not want others to see us doing something wrong. These types of incentives are how society attempts to mitigate crime.\n",
    "\n",
    "<img src='images/covey_center_habit_two.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Napoléon et la légion d'honneur:\n",
    "\n",
    "Il expose ses idées sur la Légion d’honneur et réplique au conseiller d’État Berlier, qui réservait aux monarchies les hochets et les rubans, ces distinctions indignes d’une république : « Les Romains avaient des patriciens, des chevaliers, des citoyens et des esclaves. Ils avaient pour chaque chose des costumes divers, des mœurs différentes. Ils décernaient en récompense toutes sortes de distinctions, des noms qui rappelaient des services, des couronnes murales, le triomphe ! Je défie qu’on me montre une république ancienne ou moderne dans laquelle il n’y ait pas eu de distinctions. On appelle cela des hochets ! Eh bien ! c’est avec des hochets que l’on mène les hommes. »\n",
    "\n",
    "En vertu de quoi l’ordre de la Légion d’honneur est créé le 19 mai 1802, pour récompenser les services militaires et civils. L’ordre existe toujours : le président de la République française en est aujourd’hui le grand maître."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- \"Un acte désinterressé est-il possible ?\" dans <u>Raisons pratiques: sur la théorie de l'action</u> Pierre Bourdieu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Metric in science: publications\n",
    "\n",
    "https://en.wikipedia.org/wiki/Replication_crisis\n",
    "\n",
    "https://en.wikipedia.org/wiki/Data_dredging\n",
    "\n",
    "Sociologue de l'engagement Bernard Pudal en colloque: \"quand mes entretiens ne collaient pas avec mon modèle, je les mettais pas\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Metric for a politician: point towards a hospital \n",
    "\n",
    "Charles Duhigg, <u>The power of Habits:</u> The government would build hospitals even when they weren’t needed\n",
    "\n",
    "The cue was budget money. Routine was to build a hospital. Reward was the politician being able to point and say “look what I did!” to climb the ladder of success\n",
    "\n",
    "Actually probably more complicated than that: Obama, <u>The audacity of Hope</u>: fear of humiliation by defeat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Takeaways: are metrics bad ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*\n",
    "*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
